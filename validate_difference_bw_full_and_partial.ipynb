{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.manifold import SpectralEmbedding\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Split the data into train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath_base = \"/data/yutaro/IROS/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath_big = \"/data/yutaro/IROS/sim_data_full_v11_d4_m1.mat\"\n",
    "datapath_small = \"/data/yutaro/IROS/sim_data_partial_v111_d4_m1.mat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1616064, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.426909</td>\n",
       "      <td>118.443377</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.418931</td>\n",
       "      <td>118.442513</td>\n",
       "      <td>16.030001</td>\n",
       "      <td>16.030001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.418931</td>\n",
       "      <td>118.442513</td>\n",
       "      <td>16.030001</td>\n",
       "      <td>16.030001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.404663</td>\n",
       "      <td>118.443087</td>\n",
       "      <td>16.030001</td>\n",
       "      <td>16.030001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.404663</td>\n",
       "      <td>118.443087</td>\n",
       "      <td>16.030001</td>\n",
       "      <td>16.030001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.396586</td>\n",
       "      <td>118.443348</td>\n",
       "      <td>16.060001</td>\n",
       "      <td>16.060001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.396586</td>\n",
       "      <td>118.443348</td>\n",
       "      <td>16.060001</td>\n",
       "      <td>16.060001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.391399</td>\n",
       "      <td>118.442141</td>\n",
       "      <td>16.060001</td>\n",
       "      <td>16.060001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.391399</td>\n",
       "      <td>118.442141</td>\n",
       "      <td>16.060001</td>\n",
       "      <td>16.060001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.384889</td>\n",
       "      <td>118.439220</td>\n",
       "      <td>16.090002</td>\n",
       "      <td>16.090002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0           1          2          3    4    5         6           7  \\\n",
       "0  0.426909  118.443377  16.000000  16.000000  0.0  0.0  0.418931  118.442513   \n",
       "1  0.418931  118.442513  16.030001  16.030001  1.0  1.0  0.404663  118.443087   \n",
       "2  0.404663  118.443087  16.030001  16.030001  1.0  1.0  0.396586  118.443348   \n",
       "3  0.396586  118.443348  16.060001  16.060001  1.0  1.0  0.391399  118.442141   \n",
       "4  0.391399  118.442141  16.060001  16.060001  1.0  1.0  0.384889  118.439220   \n",
       "\n",
       "           8          9  \n",
       "0  16.030001  16.030001  \n",
       "1  16.030001  16.030001  \n",
       "2  16.060001  16.060001  \n",
       "3  16.060001  16.060001  \n",
       "4  16.090002  16.090002  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big = sio.loadmat(datapath_big)\n",
    "print(big['D'].shape)\n",
    "pd.DataFrame(big['D']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(big['D'][:,:6], big['D'][:,6:], test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Normalize the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_normalization_parameters(data):\n",
    "    \"\"\"\n",
    "    Compute normalization parameters (min, max per feature)\n",
    "    :param data: matrix with data organized by rows [num_samples x num_features]\n",
    "    :return: min and max per feautre as row matrices of dimension [1 x num_variables]\n",
    "    \"\"\"\n",
    "    min_param = np.min(data, axis=0)\n",
    "    max_param = np.max(data, axis=0)\n",
    "    return np.expand_dims(min_param, 0), np.expand_dims(max_param, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data_per_row(data, min_param, max_param):\n",
    "    \"\"\"\n",
    "    Normalize a given matrix of data (samples must be organized per row)\n",
    "    :param data: input data\n",
    "    :param min_param: min (for each feature) for normalization\n",
    "    :param max_param: max (for each feature) for normalization\n",
    "    :return: normalized data, (data - min_param) / max_param - min_param\n",
    "    \"\"\"\n",
    "    # sanity checks!\n",
    "    assert len(data.shape) == 2, \"Expected the input data to be a 2D matrix\"\n",
    "    assert data.shape[1] == min_param.shape[1], \"Data - min_param size mismatch ({} vs {})\".format(data.shape[1], min_param.shape[1])\n",
    "    assert data.shape[1] == max_param.shape[1], \"Data - max_param size mismatch ({} vs {})\".format(data.shape[1], max_param.shape[1])\n",
    "\n",
    "    # TODO. Complete. Replace the line below with code to whitten the data.\n",
    "    normalized_data = np.divide(data - min_param, max_param - min_param)\n",
    "\n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_param, max_param = compute_normalization_parameters(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_param_y, max_param_y = compute_normalization_parameters(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_normalized = normalize_data_per_row(X_train, min_param, max_param)\n",
    "X_test_normalized = normalize_data_per_row(X_test, min_param, max_param)\n",
    "y_train_normalized = normalize_data_per_row(y_train, min_param_y, max_param_y)\n",
    "y_test_normalized = normalize_data_per_row(y_test, min_param_y, max_param_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.27291292 0.21652865 0.         ... 0.26044959 0.         0.32468289]\n",
      "[1.         1.         0.74025489 ... 1.         0.76048428 1.        ]\n",
      "[0.27309061 0.21714172 0.23158517 ... 0.2603582  0.29895523 0.32491984]\n",
      "[0.76699674 0.81079277 0.73955364 ... 0.76015749 0.76083998 0.79194657]\n"
     ]
    }
   ],
   "source": [
    "print(np.min(X_test_normalized, axis=1))\n",
    "print(np.max(X_test_normalized, axis=1))\n",
    "print(np.min(y_test_normalized, axis=1))\n",
    "print(np.max(y_test_normalized, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Implement the transition model \n",
    "\n",
    "- Given the query point $(x, a)$, we want to find where $(x,a)$ will go next.\n",
    "- The function $(x_{next}, a_{next}) = f((x,a))$ should be implemented as follows:\n",
    "  - Step1: Find K1 (=1000) nearest points in training data. Let the closest pair to $(x,a)$ be $(x_h, a_h)$\n",
    "  - Step2: Diffusin map is created based on these 1000 points, which yields a reduced dimensional data (m=3 is used in the original paper)\n",
    "  - Step3: K2 (=100) closest points in the reduced dimensional data to the $(x_h, a_h)$ in the diffusion map is found\n",
    "  - Step4: Perform GP regression on these 100 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition_model(x_query, X_train_normalized, y_train_normalized, k1=1000, m=3, k2=100):\n",
    "    file_path = os.path.join(datapath_base, 'nbrs.pkl')\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'rb') as f:\n",
    "            nbrs = pickle.load(f)\n",
    "    else:\n",
    "        nbrs = NearestNeighbors(n_neighbors=k1, algorithm='ball_tree').fit(X_train_normalized)\n",
    "        print(\"This is going to take about 15 min...\")\n",
    "        with open('nbrs.pkl', 'wb') as f:\n",
    "            pickle.dump(nbrs, f)\n",
    "    \n",
    "    # Step1: Find K1 (=1000) nearest points in training data. Let the closest pair to $(x,a)$ be $(x_h, a_h)$\n",
    "    distances, indices = nbrs.kneighbors(x_query.reshape(1,-1))\n",
    "    X_selected = X_train_normalized[indices.reshape(-1), :]\n",
    "    y_selected = y_train_normalized[indices.reshape(-1), :]\n",
    "    \n",
    "    # Step2: Diffusin map is created based on these 1000 points, which yields a reduced dimensional data\n",
    "    embedding = SpectralEmbedding(n_components=m) \n",
    "    X_spectral = embedding.fit_transform(X_selected) \n",
    "    # y_spectral = embedding.fit_transform(y_selected) \n",
    "    \n",
    "    # Step3: K2 (=100) closest points in the reduced dimensional data to the $(x_h, a_h)$ in the diffusion map is found\n",
    "    nbrs_diffusion = NearestNeighbors(n_neighbors=k2, algorithm='ball_tree').fit(X_spectral)\n",
    "    distances_diffusion, indices_diffusion = nbrs_diffusion.kneighbors(X_spectral[0, :].reshape(1, -1))\n",
    "\n",
    "    # Step4: Perform GP regression on these 100 points.\n",
    "    X_GP_input = X_spectral[indices_diffusion.reshape(-1), :]\n",
    "    y_GP_input = y_selected[indices_diffusion.reshape(-1), :]\n",
    "    #print(\"X_GP_input.shape: {}\".format(X_GP_input.shape))\n",
    "    #print(\"y_GP_input.shape: {}\".format(y_GP_input.shape))\n",
    "\n",
    "    gpr = GaussianProcessRegressor(kernel=None,random_state=0).fit(X_GP_input, y_GP_input)\n",
    "    y_pred = gpr.predict(X_spectral[0,:].reshape(1,m)) \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4367823  0.76776211 0.27291292 0.28221233 0.5        1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test_normalized[0,:].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_GP_input.shape: (100, 3)\n",
      "y_GP_input.shape: (100, 4)\n",
      "y_new.shape: (1, 4)\n"
     ]
    }
   ],
   "source": [
    "y_new = transition_model(X_test_normalized[0,:].reshape(1,-1), X_train_normalized, y_train_normalized) \n",
    "print(\"y_new.shape: {}\".format(y_new.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Validate that the small data is indeed different from the big data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mse(X_test_normalized, X_train_normalized, y_train_normalized):\n",
    "    mse = 0\n",
    "    for i in range(X_test_normalized.shape[0]):\n",
    "        y_new = transition_model(X_test_normalized[i,:].reshape(1,-1), X_train_normalized, y_train_normalized)\n",
    "        #print(y_test_normalized[i, :].reshape(1,-1).shape)\n",
    "        #print(y_new.shape)\n",
    "        mse += np.mean(np.linalg.norm(y_test_normalized[i, :].reshape(1,-1) - y_new)**2)\n",
    "        #print(mse)\n",
    "    return mse / X_test_normalized.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/manifold/spectral_embedding_.py:234: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mse_big = calc_mse(X_test_normalized, X_train_normalized, y_train_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step3.2: Get the small data and calculate mse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83888, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.118160</td>\n",
       "      <td>-0.005951</td>\n",
       "      <td>16.030001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.118159</td>\n",
       "      <td>-0.005951</td>\n",
       "      <td>16.030001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.118159</td>\n",
       "      <td>-0.005951</td>\n",
       "      <td>16.030001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.118159</td>\n",
       "      <td>-0.005951</td>\n",
       "      <td>16.060001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.118159</td>\n",
       "      <td>-0.005951</td>\n",
       "      <td>16.060001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.118159</td>\n",
       "      <td>-0.005951</td>\n",
       "      <td>16.060001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.118159</td>\n",
       "      <td>-0.005951</td>\n",
       "      <td>16.060001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.118158</td>\n",
       "      <td>-0.005951</td>\n",
       "      <td>16.090002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.118158</td>\n",
       "      <td>-0.005951</td>\n",
       "      <td>16.090002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>0.118158</td>\n",
       "      <td>-0.005951</td>\n",
       "      <td>16.090002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2          3    4    5         6         7  \\\n",
       "0  0.000215  0.118160 -0.005951  16.030001  1.0 -1.0  0.000233  0.118159   \n",
       "1  0.000233  0.118159 -0.005951  16.030001  1.0 -1.0  0.000257  0.118159   \n",
       "2  0.000257  0.118159 -0.005951  16.060001  1.0 -1.0  0.000295  0.118159   \n",
       "3  0.000295  0.118159 -0.005951  16.060001  1.0 -1.0  0.000334  0.118158   \n",
       "4  0.000334  0.118158 -0.005951  16.090002  1.0 -1.0  0.000384  0.118158   \n",
       "\n",
       "          8          9  \n",
       "0 -0.005951  16.030001  \n",
       "1 -0.005951  16.060001  \n",
       "2 -0.005951  16.060001  \n",
       "3 -0.005951  16.090002  \n",
       "4 -0.005951  16.090002  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small = sio.loadmat(datapath_small)\n",
    "print(small['D'].shape)\n",
    "pd.DataFrame(small['D']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small, X_test_small, y_train_small, y_test_small = train_test_split(small['D'][:,:6], small['D'][:,6:], test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_param_small, max_param_small = compute_normalization_parameters(X_train_small)\n",
    "min_param_y_small, max_param_y_small = compute_normalization_parameters(y_train_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_normalized_small = normalize_data_per_row(X_train_small, min_param_small, max_param_small)\n",
    "X_test_normalized_small = normalize_data_per_row(X_test_small, min_param_small, max_param_small)\n",
    "y_train_normalized_small = normalize_data_per_row(y_train_small, min_param_y_small, max_param_y_small)\n",
    "y_test_normalized_small = normalize_data_per_row(y_test_small, min_param_y_small, max_param_y_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mse_big = calc_mse(X_test_normalized_small, X_train_normalized, y_train_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 6)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_normalized_small[:100,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
